# GPU 选择推荐

## 📊 项目GPU需求分析

### 显存需求

根据设计文档，各模型的GPU显存需求：

| 模型 | 参数量 | 显存需求 | 用途 |
|------|--------|----------|------|
| SPECTER2 | 125M | 4GB | 密集检索 |
| SciBERT | 110M | 4GB | 双编码器 |
| ColBERT | 110M | 8GB | 重排序 |
| Cross-Encoder | 67M | 6GB | 最终排序 |

**实际需求**：
- 推理/索引构建：**8GB+** 足够
- Fine-tuning训练：**16GB+** 推荐（批量训练需要更多显存）
- 批量处理：**24GB+** 更安全（可以增大batch size加速）

### 计算时间估算（基于V100）

| 任务 | 时间 | 说明 |
|------|------|------|
| SciBERT Fine-tuning | 3-4小时 | 12,844样本 |
| SPECTER2 Fine-tuning | 4小时 | 12,844样本 |
| Cross-Encoder Fine-tuning | 5-6小时 | 51,376样本对 |
| 索引构建 | 1-2小时 | 4,504篇论文 |
| 实验运行 | 2-3小时 | 测试集评估 |

**总计：15-20 GPU小时**

### 性能对比（相对于V100）

| 显卡 | 显存 | 相对性能 | 推荐场景 |
|------|------|----------|----------|
| H100 | 80GB | ~3x | 超预算，不推荐 |
| A100 | 80GB | ~2.5x | 预算充足可选 |
| A100 | 40GB | ~2.5x | 预算充足可选 |
| A30 | 24GB | ~1.5x | **性价比高** |
| A10 | 24GB | ~1.3x | **性价比高** |
| 3090 | 24GB | ~1.0x | **性价比最高** |
| 4090 | 24GB | ~1.2x | 比3090快20% |
| 3080 | 10GB | ~0.8x | 显存可能不足 |

## 🎯 推荐方案

### 方案1：性价比最高 ⭐⭐⭐⭐⭐

**3090-24G**（图片中高亮的选项）

**优势**：
- ✅ 24GB显存完全够用
- ✅ 价格相对便宜
- ✅ 性能稳定可靠
- ✅ 社区支持好

**预计时间**：
- Fine-tuning: 12-15小时（3个模型）
- 总时间: 15-18小时

**适用场景**：预算有限，追求性价比

---

### 方案2：速度优先 ⭐⭐⭐⭐

**4090-24G**

**优势**：
- ✅ 24GB显存充足
- ✅ 比3090快约20%
- ✅ 最新架构，效率更高

**预计时间**：
- Fine-tuning: 10-12小时
- 总时间: 13-15小时

**适用场景**：想更快完成任务

---

### 方案3：专业级（预算充足）⭐⭐⭐⭐

**A30-24G 或 A10-24G**

**优势**：
- ✅ 专业级GPU，稳定性好
- ✅ 24GB显存
- ✅ 比3090快30-50%
- ✅ 支持多实例（如果平台支持）

**预计时间**：
- Fine-tuning: 8-10小时
- 总时间: 11-13小时

**适用场景**：预算充足，追求速度和稳定性

---

### 方案4：极致性能（不推荐）⭐⭐

**A100-80GB 或 H100-80GB**

**优势**：
- ✅ 性能最强
- ✅ 显存超大（可以增大batch size）

**劣势**：
- ❌ 价格昂贵（可能是3090的3-5倍）
- ❌ 对于这个项目来说性能过剩

**预计时间**：
- Fine-tuning: 6-8小时
- 总时间: 9-11小时

**适用场景**：预算非常充足，或需要同时跑多个实验

---

## 💡 最终推荐

### 首选：**3090-24G** ⭐⭐⭐⭐⭐

**理由**：
1. 24GB显存完全满足需求（16GB+要求）
2. 性价比最高
3. 预计15-18小时完成所有任务（1-2天）
4. 图片中已高亮显示，可能是平台推荐

### 备选：**4090-24G** ⭐⭐⭐⭐

如果预算允许，4090可以节省2-3小时，但价格可能高30-50%

### 不推荐

- **3080-10G/12G**: 显存可能不足，训练时可能OOM
- **3060系列**: 性能太弱，时间会很长
- **H100/A100**: 价格太贵，性能过剩

## 📝 使用建议

1. **批量大小调整**：
   - 24GB显存：batch_size=16-32
   - 16GB显存：batch_size=8-16
   - 10GB显存：batch_size=4-8（可能不够）

2. **混合精度训练**：
   - 使用FP16可以节省显存，加速训练
   - 3090/4090都支持

3. **分阶段训练**：
   - 可以先训练SciBERT（3-4小时）
   - 再训练SPECTER2（4小时）
   - 最后训练Cross-Encoder（5-6小时）
   - 不需要同时运行

## ⏱️ 时间估算总结

| 显卡 | 总时间 | 成本（估算） | 性价比 |
|------|--------|-------------|--------|
| 3090-24G | 15-18小时 | 低 | ⭐⭐⭐⭐⭐ |
| 4090-24G | 13-15小时 | 中 | ⭐⭐⭐⭐ |
| A30-24G | 11-13小时 | 中高 | ⭐⭐⭐ |
| A100-40G | 9-11小时 | 高 | ⭐⭐ |

**结论：3090-24G是最佳选择！** 🎯

