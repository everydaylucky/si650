# æ•°æ®é›†é‡æ–°ç»„ç»‡æŒ‡å—

## ğŸ“Š æ–°æ•°æ®æ ¼å¼

ä¸ºäº†ä¾¿äºç´¢å¼•ï¼Œæˆ‘ä»¬å°†æ•°æ®é‡æ–°ç»„ç»‡ä¸ºä¸¤ä¸ªç‹¬ç«‹æ–‡ä»¶ï¼š

### 1. `corpus.json` - ç´¢å¼•æ–‡æ¡£æ–‡ä»¶
åŒ…å«æ‰€æœ‰å”¯ä¸€æ–‡æ¡£ï¼Œç”¨äºæ„å»ºæ£€ç´¢ç´¢å¼•ã€‚

**æ ¼å¼**ï¼š
```json
[
  {
    "id": "2009.05166",
    "paper_id": "2009.05166",
    "title": "FILTER: An Enhanced Fusion Method...",
    "abstract": "...",
    "categories": ["cs.CL"],
    "year": 2020
  },
  ...
]
```

**ç‰¹ç‚¹**ï¼š
- âœ… åŒ…å«æ‰€æœ‰å”¯ä¸€æ–‡æ¡£ï¼ˆ4504ä¸ªï¼‰
- âœ… å»é‡ï¼Œé¿å…é‡å¤ç´¢å¼•
- âœ… å¯ä»¥å¤ç”¨ï¼Œå¤šä¸ªå®éªŒå…±äº«åŒä¸€ç´¢å¼•

### 2. `test.json` - æµ‹è¯•æ•°æ®æ–‡ä»¶
åªåŒ…å«æŸ¥è¯¢å’Œ ground truthï¼Œä¸åŒ…å«æ‰€æœ‰ candidatesã€‚

**æ ¼å¼**ï¼š
```json
[
  {
    "sample_id": "2010.11934_cite_00000",
    "source_paper": {
      "id": "2010.11934",
      "title": "...",
      "abstract": "...",
      "categories": ["cs.CL"],
      "year": 2020
    },
    "citation_context": {
      "text": "Metrics for XLM...",
      "context_before": "",
      "context_after": "All other metrics...",
      "section": "Results"
    },
    "target_paper_id": "2009.05166"
  },
  ...
]
```

**ç‰¹ç‚¹**ï¼š
- âœ… æ–‡ä»¶æ›´å°ï¼ŒåŠ è½½æ›´å¿«
- âœ… åªåŒ…å«å¿…è¦ä¿¡æ¯ï¼ˆæŸ¥è¯¢ + ground truthï¼‰
- âœ… æ¸…æ™°çš„åˆ†ç¦»ï¼šç´¢å¼• vs è¯„ä¼°

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### 1. é‡æ–°ç»„ç»‡æ•°æ®

```bash
# ä» data/full æ ¼å¼è½¬æ¢
python scripts/reorganize_data_for_indexing.py \
    --input data/full/test.json \
    --output data/full_indexed
```

**è¾“å‡º**ï¼š
- `data/full_indexed/corpus.json` - ç´¢å¼•æ–‡æ¡£
- `data/full_indexed/test.json` - æµ‹è¯•æ•°æ®
- `data/full_indexed/metadata.json` - å…ƒæ•°æ®

### 2. è¿è¡Œå®éªŒ

ä½¿ç”¨æ–°æ ¼å¼è¿è¡Œå®éªŒï¼š

```bash
# ä½¿ç”¨æ–°æ ¼å¼æ•°æ®
python scripts/run_all_experiments.py \
    --experiment exp_6_1b_1_context_before \
    --data_dir data/full_indexed
```

**ä»£ç ä¼šè‡ªåŠ¨æ£€æµ‹**ï¼š
- å¦‚æœå­˜åœ¨ `corpus.json` å’Œ `test.json`ï¼Œä½¿ç”¨æ–°æ ¼å¼
- å¦åˆ™ï¼Œä½¿ç”¨ä¼ ç»Ÿæ ¼å¼ï¼ˆä»æµ‹è¯•æ•°æ®ä¸­æå–æ–‡æ¡£ï¼‰

## ğŸ“ˆ ä¼˜åŠ¿å¯¹æ¯”

| ç‰¹æ€§ | æ—§æ ¼å¼ | æ–°æ ¼å¼ |
|------|--------|--------|
| **ç´¢å¼•æ–‡æ¡£** | ä»æµ‹è¯•æ•°æ®ä¸­æå– | ç‹¬ç«‹çš„ `corpus.json` |
| **æ–‡ä»¶å¤§å°** | 278MB (test.json) | ~50MB (corpus) + ~10MB (test) |
| **åŠ è½½é€Ÿåº¦** | æ…¢ï¼ˆéœ€è¦è§£ææ‰€æœ‰ candidatesï¼‰ | å¿«ï¼ˆåªåŠ è½½å¿…è¦æ•°æ®ï¼‰ |
| **ç´¢å¼•å¤ç”¨** | âŒ æ¯æ¬¡é‡æ–°æ„å»º | âœ… å¯ä»¥å¤ç”¨ |
| **æ•°æ®åˆ†ç¦»** | âŒ æ··åˆåœ¨ä¸€èµ· | âœ… æ¸…æ™°çš„åˆ†ç¦» |
| **å»é‡** | âš ï¸ éœ€è¦æ‰‹åŠ¨å¤„ç† | âœ… è‡ªåŠ¨å»é‡ |

## ğŸ”„ æ•°æ®æµç¨‹

### æ—§æ ¼å¼æµç¨‹
```
test.json (278MB)
  â†“
è§£ææ‰€æœ‰ candidates (188,800ä¸ª)
  â†“
æå–å”¯ä¸€æ–‡æ¡£ (4,504ä¸ª)
  â†“
æ„å»ºç´¢å¼•
  â†“
è¯„ä¼°
```

### æ–°æ ¼å¼æµç¨‹
```
corpus.json (50MB) â†’ æ„å»ºç´¢å¼• (ä¸€æ¬¡æ€§)
test.json (10MB)   â†’ è¯„ä¼° (å¿«é€ŸåŠ è½½)
```

## ğŸ“ æ–‡ä»¶ç»“æ„

```
data/
â”œâ”€â”€ full/                    # åŸå§‹æ•°æ®
â”‚   â”œâ”€â”€ test.json           # 278MB (åŒ…å«æ‰€æœ‰ candidates)
â”‚   â”œâ”€â”€ val.json
â”‚   â””â”€â”€ train.json
â”‚
â””â”€â”€ full_indexed/            # é‡æ–°ç»„ç»‡åçš„æ•°æ®
    â”œâ”€â”€ corpus.json         # 50MB (æ‰€æœ‰å”¯ä¸€æ–‡æ¡£)
    â”œâ”€â”€ test.json           # 10MB (åªåŒ…å«æŸ¥è¯¢å’Œ ground truth)
    â””â”€â”€ metadata.json       # å…ƒæ•°æ®
```

## âœ… éªŒè¯

è¿è¡ŒéªŒè¯è„šæœ¬ï¼š

```bash
python -c "
import json
from pathlib import Path

corpus_file = Path('data/full_indexed/corpus.json')
test_file = Path('data/full_indexed/test.json')

# æ£€æŸ¥æ–‡ä»¶
with open(corpus_file) as f:
    corpus = json.load(f)
print(f'âœ“ corpus.json: {len(corpus)} ä¸ªæ–‡æ¡£')

with open(test_file) as f:
    test_data = json.load(f)
print(f'âœ“ test.json: {len(test_data)} ä¸ªæ ·æœ¬')

# éªŒè¯ ground truth éƒ½åœ¨ç´¢å¼•ä¸­
corpus_ids = {doc['id'] for doc in corpus}
test_ids = {s['target_paper_id'] for s in test_data if s.get('target_paper_id')}
missing = test_ids - corpus_ids

if missing:
    print(f'âš ï¸  è­¦å‘Š: {len(missing)} ä¸ª ground truth ä¸åœ¨ç´¢å¼•ä¸­')
else:
    print(f'âœ“ æ‰€æœ‰ ground truth éƒ½åœ¨ç´¢å¼•ä¸­')
"
```

## ğŸ¯ ä¸‹ä¸€æ­¥

1. **é‡æ–°ç»„ç»‡æ‰€æœ‰æ•°æ®**ï¼š
   ```bash
   # é‡æ–°ç»„ç»‡ train, val, test
   python scripts/reorganize_data_for_indexing.py --input data/full/train.json --output data/full_indexed_train
   python scripts/reorganize_data_for_indexing.py --input data/full/val.json --output data/full_indexed_val
   python scripts/reorganize_data_for_indexing.py --input data/full/test.json --output data/full_indexed
   ```

2. **è¿è¡Œå®éªŒ**ï¼š
   ```bash
   python scripts/run_all_experiments.py --experiment exp_6_1b_1_context_before --data_dir data/full_indexed
   ```

3. **å¯¹æ¯”æ€§èƒ½**ï¼š
   - ä½¿ç”¨æ–°æ ¼å¼åº”è¯¥æ›´å¿«
   - ç´¢å¼•å¯ä»¥å¤ç”¨ï¼ŒèŠ‚çœæ—¶é—´
   - è¯„ä¼°ç»“æœåº”è¯¥ä¸€è‡´

