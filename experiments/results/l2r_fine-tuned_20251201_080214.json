{
  "experiment_id": "l2r_fine-tuned_20251201_080214",
  "experiment_name": "LightGBM L2R (Fine-tuned)",
  "model_type": "l2r",
  "variant": "fine-tuned",
  "timestamp": "2025-12-01T08:02:14.588571",
  "config": {
    "stage1": {
      "bm25": {
        "b": 0.75,
        "k1": 1.5
      },
      "specter2": {
        "faiss_nlist": 100,
        "faiss_nprobe": 10,
        "model_name": "allenai/specter2",
        "fine_tuned_path": "experiments/checkpoints/specter2"
      },
      "top_k": 1000,
      "use_bm25": true,
      "use_prf": false,
      "use_specter2": true,
      "use_tfidf": true
    },
    "stage2": {
      "bi_encoder": {
        "fine_tuned_path": "experiments/checkpoints/scibert",
        "model_name": "allenai/scibert_scivocab_uncased"
      },
      "rrf": {
        "k": 60
      },
      "top_k": 50,
      "use_bi_encoder": true,
      "use_colbert": false,
      "use_rrf": false
    },
    "stage3": {
      "cross_encoder": {
        "fine_tuned_path": "experiments/checkpoints/cross_encoder",
        "model_name": "cross-encoder/ms-marco-MiniLM-L-12-v2"
      },
      "top_k": 20,
      "use_cross_encoder": false,
      "use_l2r": true,
      "l2r": {
        "model_path": "/hy-tmp/final_test/experiments/checkpoints/l2r/ft/l2r_model.txt"
      }
    },
    "training": {
      "scibert": {
        "batch_size": 16,
        "early_stopping_patience": 2,
        "epochs": 3,
        "learning_rate": "2e-5",
        "warmup_steps": 100
      },
      "train_cross_encoder": false,
      "train_l2r": true,
      "train_scibert": false,
      "train_specter2": false
    }
  },
  "metrics": {
    "mrr": 0.29218527184874854,
    "recall@5": 0.3855932203389831,
    "recall@10": 0.5148305084745762,
    "recall@20": 0.5995762711864406,
    "recall@50": 0.5995762711864406,
    "precision@10": 0.05148305084745762,
    "precision@20": 0.02997881355932203,
    "ndcg@10": 0.3399129632597014,
    "ndcg@20": 0.36172161530169145
  },
  "training_info": {
    "model_path": "/hy-tmp/final_test/experiments/checkpoints/l2r/ft/l2r_model.txt",
    "status": "completed"
  },
  "model_path": "/hy-tmp/final_test/experiments/checkpoints/l2r/ft/l2r_model.txt",
  "notes": "LightGBM Learning-to-Rank with fine-tuned features"
}